{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = \"datasets/housing\"\n",
    "HOUSING_URL=DOWNLOAD_ROOT + HOUSING_PATH +\"/housing.tgz\"\n",
    "def fetch_housing_data(housing_url=HOUSING_URL,housing_path=HOUSING_PATH):\n",
    "    '''从网络获取数据下载到本地目录'''\n",
    "    housing_path=HOUSING_PATH\n",
    "    housing_url=HOUSING_URL\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path,\"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url,tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(housing_path)\n",
    "    housing_tgz.close()\n",
    "    \n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    '''从文件读取数据并返回dataframe对象'''\n",
    "    csv_path=os.path.join(housing_path,\"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch_housing_data()\n",
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"ocean_proximity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data,test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data)*test_ratio)\n",
    "    test_indices=shuffled_indices[:test_set_size]\n",
    "    train_indices=shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices],data.iloc[test_indices]\n",
    "\n",
    "train_set,test_set=split_train_test(housing,0.2)\n",
    "print (len(train_set),\"train+\",len(test_set),\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def test_set_check(identifier,test_ratio,hash):\n",
    "    return hash(np.int64(identifier)).digest()[-1]<256*test_ratio\n",
    "\n",
    "def split_train_test_by_id(data,test_tatio,id_column,hash=hashlib.md5):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_:test_set_check(id_,test_tatio,hash))\n",
    "    return data.loc[~in_test_set],data.loc[in_test_set]\n",
    "\n",
    "#方法一：使用行索引作为唯一标识符，需要确保在数据集末尾添加新数据，并且不会删除任何行\n",
    "housing_with_id = housing.reset_index()\n",
    "#方法二：使用经纬度作为唯一标识符，最稳定的特征\n",
    "housing_with_id[\"id\"] = housing[\"longitude\"]*1000+housing[\"latitude\"]\n",
    "train_set,test_set = split_train_test_by_id(housing_with_id,0.2,\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "housing['income_cat']=np.ceil(housing['median_income']/1.5)\n",
    "housing['income_cat'].where(housing['income_cat']<5,5.0,inplace=True)\n",
    "\n",
    "train_set,test_set=train_test_split(housing,test_size=0.2,random_state=42)\n",
    "split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for train_index,test_index in split.split(housing,housing['income_cat']):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "print(housing['income_cat'].value_counts()/len(housing))\n",
    "print(strat_test_set['income_cat'].value_counts()/len(strat_test_set))\n",
    "print(test_set['income_cat'].value_counts()/len(strat_test_set))\n",
    "\n",
    "for set in (strat_train_set,strat_test_set):\n",
    "    set.drop([\"income_cat\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从数据探索和可视化获得洞见"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将地理数据可视化\n",
    "housing = strat_train_set.copy()\n",
    "housing.plot(kind='scatter',x='longitude',y='latitude',alpha=0.1,\n",
    "            s=housing['population']/100,label='population',\n",
    "            c='median_house_value',cmap=plt.get_cmap('jet'),colorbar=True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#寻找相关性\n",
    "corr_matrix = housing.corr()\n",
    "corr_matrix['median_house_value'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "attributes =['median_house_value','median_income','total_rooms','housing_median_age']\n",
    "scatter_matrix(housing[attributes],figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind='scatter',x='median_income',y='median_house_value',alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#试验不同属性的组合\n",
    "housing['rooms_per_household']=housing['total_rooms']/housing['households']#家庭每户平均房间数\n",
    "housing['bedrooms_per_room']=housing['total_bedrooms']/housing['total_rooms']#卧室占比\n",
    "housing['population_per_household']=housing['population']/housing['households']#每个家庭人口数\n",
    "corr_matrix=housing.corr()\n",
    "corr_matrix['median_house_value'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习算法的数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据清理\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "housing = strat_train_set.drop(\"median_house_value\",axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "median=housing[\"total_bedrooms\"].median()\n",
    "housing[\"total_bedrooms\"].fillna(median)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "housing_num=housing.drop(\"ocean_proximity\",axis=1) #创建一个没有文本属性的数据副本\n",
    "imputer.fit(housing_num)\n",
    "print(imputer.statistics_) \n",
    "print(housing_num.median().values)\n",
    "X=imputer.transform(housing_num)\n",
    "housing_tr = pd.DataFrame(X,columns=housing_num.columns)#将清洗完的ndarray转回dataframe\n",
    "\n",
    "#处理文本和分类属性\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "#文本转数值编码\n",
    "encoder = LabelEncoder()\n",
    "housing_cat = housing[\"ocean_proximity\"]\n",
    "housing_cat_encoded = encoder.fit_transform(housing_cat)\n",
    "print(encoder.classes_)\n",
    "\n",
    "#数值编码转独热编码\n",
    "encoder =OneHotEncoder(categories='auto')\n",
    "#返回一个scipy稀疏矩阵，用于存储大量0\n",
    "housing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1,1)) \n",
    "\n",
    "#文本转独热编码\n",
    "encoder = LabelBinarizer()\n",
    "housing_cat_1hot = encoder.fit_transform(housing_cat)\n",
    "print(housing_cat_1hot)\n",
    "\n",
    "#自定义转换器\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "rooms_ix,bedrooms_ix,population_ix,household_ix = 3,4,5,6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,add_bedrooms_per_room = True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "    def transform(self,X,y = None):\n",
    "        rooms_per_household = X[:,rooms_ix]/X[:,household_ix]\n",
    "        population_per_household = X[:,population_ix]/X[:,household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:,bedrooms_ix]/X[:,rooms_ix]\n",
    "            return np.c_[X,rooms_per_household,population_per_household,bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X,rooms_per_household,population_per_household]\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#转换流水线-处理数值\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder',CombinedAttributesAdder()),\n",
    "    ('std_scaler',StandardScaler())\n",
    "])\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "\n",
    "#完整处理数值和分类属性的流水线\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "num_attribs=list(housing_num)\n",
    "cat_attribs=[\"ocean_proximity\"]\n",
    "\n",
    "class DataFrameSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names=attribute_names\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "class MyLabelBinarizer(BaseEstimator,TransformerMixin):\n",
    "    '''\n",
    "    使用LabelBinarizer导致参数报错问题\n",
    "    https://stackoverflow.com/questions/46162855/fit-transform-takes-2-positional-arguments-but-3-were-given-with-labelbinarize'''\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.encoder = LabelBinarizer(*args, **kwargs)\n",
    "    def fit(self, x, y=0):\n",
    "        self.encoder.fit(x)\n",
    "        return self\n",
    "    def transform(self, x, y=0):\n",
    "        return self.encoder.transform(x)\n",
    "    \n",
    "num_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(num_attribs)),\n",
    "    ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder',CombinedAttributesAdder()),\n",
    "    ('std_scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(cat_attribs)),\n",
    "    ('label_binarizer',MyLabelBinarizer()),\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"num_pipline\",num_pipeline),\n",
    "    (\"cat_pipline\",cat_pipeline),\n",
    "])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "housing_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 选择和训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练和评估训练集\n",
    "#使用线性回归模型进行拟合\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared,housing_labels)\n",
    "\n",
    "#查看预测值和实际值\n",
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "print(\"Predictions:\\t\",lin_reg.predict(some_data_prepared))\n",
    "print(\"Labels:\\t\\t\",list(some_labels))\n",
    "\n",
    "#使用均方误差MSE来评估效果\n",
    "from sklearn.metrics import mean_squared_error\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels,housing_predictions)\n",
    "\n",
    "#使用均方根误差rmse来观测误差大小\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(lin_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "均方误差MSE:(线性回归的代价函数)\n",
    "$$\\frac 1m\\sum_{i=1}^m(y_i-\\hat y_i)^2$$\n",
    "\n",
    "\n",
    "数据结果欠拟合，需要增加信息完备性-新增特征，或者换用更强的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用决策树回归模型进行拟合\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prepared,housing_labels)\n",
    "housing_predctions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels,housing_predctions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "print(tree_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用交叉验证来更好的进行评估\n",
    "\n",
    "#决策树K折交叉验证\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg,housing_prepared,housing_labels,\n",
    "                        scoring=\"neg_mean_squared_error\",cv=10)\n",
    "tree_rmse_scores=np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\",scores)\n",
    "    print(\"Mean:\",scores.mean())\n",
    "    print(\"Standard deviation:\",scores.std())\n",
    "    \n",
    "display_scores(tree_rmse_scores)\n",
    "\n",
    "#线性回归K折交叉验证\n",
    "lin_scores = cross_val_score(lin_reg,housing_prepared,housing_labels,\n",
    "                        scoring=\"neg_mean_squared_error\",cv=10)\n",
    "lin_rmse_scores=np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论：决策树模型严重过拟合，以至于在测试集上表现的比线性回归还要糟糕\n",
    "\n",
    "试试集成模型-随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor(n_estimators=10)\n",
    "forest_reg.fit(housing_prepared,housing_labels)\n",
    "housing_predctions = forest_reg.predict(housing_prepared)\n",
    "forest_mse = mean_squared_error(housing_labels,housing_predctions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "scores = cross_val_score(forest_reg,housing_prepared,housing_labels,\n",
    "                        scoring=\"neg_mean_squared_error\",cv=10)\n",
    "forest_rmse_scores=np.sqrt(-scores)\n",
    "\n",
    "print(forest_rmse)\n",
    "\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试各种机器学习模型-直到筛出2-5个有效模型\n",
    "\n",
    "序列化存储\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(forest_reg,\"my_model.pkl\")\n",
    "\n",
    "my_model_loaded =joblib.load(\"my_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 微调模型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#网格搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators':[3,10,30],'max_features':[2,4,6,8]},\n",
    "    {'bootstrap':[False],'n_estimators':[3,10],'max_features':[2,3,4]}\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg,param_grid,cv=5,\n",
    "                          scoring='neg_mean_squared_error')\n",
    "grid_search.fit(housing_prepared,housing_labels)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n",
    "cvers = grid_search.cv_results_\n",
    "\n",
    "for mean_score,params in zip(cvers[\"mean_test_score\"],cvers[\"params\"]):\n",
    "    print(np.sqrt(-mean_score),params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机搜索 RandomizedSearchCV\n",
    "#集成方法 随机森林\n",
    "#分析最佳模型及其错误\n",
    "feature_importances =grid_search.best_estimator_.feature_importances_\n",
    "extra_attribs = [\"rooms_per_hhold\",\"pop_per_hhold\",\"bedrooms_per_room\"]\n",
    "cat_one_hot_attribs = list(encoder.classes_)\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances,attributes),reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通过测试集评估系统\n",
    "final_model =grid_search.best_estimator_\n",
    "X_test = strat_test_set.drop(\"median_house_value\",axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test,final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print (final_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 启动、监控和维护系统"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
